---
layout: post
title:  "Independent Component Analysis(ICA)"
date:   2019-08-5 10:50:43
categories: 机器学习
tags: 算法 降维 数据处理
---

* content
{:toc}

主要介绍了ICA的原理。




## 1、核心思想

ICA(Independent Component Analysis,独立成分分析)，希望能利用很少的先验知识将混合信息分离，变成独立分量。也可以说希望能找到事物的一种合理表示，使各分量最大地独立。

## 2、背景问题

ICA一个经典问题是鸡尾酒宴会问题。假设宴会中有n个人，他们同时说话，我们用声音接收器收集他们的声音，得到一组数据{<a href="https://www.codecogs.com/eqnedit.php?latex={x^{(i)};i=1,2,...,m}" target="_blank"><img src="https://latex.codecogs.com/gif.latex?{x^{(i)};i=1,2,...,m}" title="{x^{(i)};i=1,2,...,m}" /></a>}，i表示采样的时间顺序。也就是我们采集了m个时刻的数据，每个时刻的数据都是n维的（有n个特征）。

这组数据的本质是n个信号源，只不过信号混合起来了。现在我们假设这n个信号源为<a href="https://www.codecogs.com/eqnedit.php?latex=s=(s_{1},s_{2},...,s_{n})^{T},s\in&space;R^{n}" target="_blank"><img src="https://latex.codecogs.com/gif.latex?s=(s_{1},s_{2},...,s_{n})^{T},s\in&space;R^{n}" title="s=(s_{1},s_{2},...,s_{n})^{T},s\in R^{n}" /></a>，每一维都是一个人的声音，每个人的声音信号都独立。A是一个未知的混合矩阵，用来叠加信号s,这样

<a href="https://www.codecogs.com/eqnedit.php?latex=x=[x^{(1)},x^{(2)},...,x^{(m)}]=[As^{(1)},As^{(2)},...,As^{(m)}]=A\begin{bmatrix}&space;s_{1}^{(1)}&space;&&space;s_{1}^{(2)}&space;&&space;...&space;&s_{1}^{(m)}&space;\\&space;s_{2}^{(1)}&space;&&space;s_{2}^{(2)}&space;&&space;...&space;&s_{2}^{(m)}&space;\\&space;...&space;&&space;...&space;&&space;...&space;&&space;\\&space;s_{n}^{(1)}&space;&&space;s_{n}^{(2)}&space;&&space;...&space;&s_{n}^{(m)}&space;\end{bmatrix}" target="_blank"><img src="https://latex.codecogs.com/gif.latex?x=[x^{(1)},x^{(2)},...,x^{(m)}]=[As^{(1)},As^{(2)},...,As^{(m)}]=A\begin{bmatrix}&space;s_{1}^{(1)}&space;&&space;s_{1}^{(2)}&space;&&space;...&space;&s_{1}^{(m)}&space;\\&space;s_{2}^{(1)}&space;&&space;s_{2}^{(2)}&space;&&space;...&space;&s_{2}^{(m)}&space;\\&space;...&space;&&space;...&space;&&space;...&space;&&space;\\&space;s_{n}^{(1)}&space;&&space;s_{n}^{(2)}&space;&&space;...&space;&s_{n}^{(m)}&space;\end{bmatrix}" title="x=[x^{(1)},x^{(2)},...,x^{(m)}]=[As^{(1)},As^{(2)},...,As^{(m)}]=A\begin{bmatrix} s_{1}^{(1)} & s_{1}^{(2)} & ... &s_{1}^{(m)} \\ s_{2}^{(1)} & s_{2}^{(2)} & ... &s_{2}^{(m)} \\ ... & ... & ... & \\ s_{n}^{(1)} & s_{n}^{(2)} & ... &s_{n}^{(m)} \end{bmatrix}" /></a>

x是一个矩阵，每个列向量是<a href="https://www.codecogs.com/eqnedit.php?latex=x^{(i)}" target="_blank"><img src="https://latex.codecogs.com/gif.latex?x^{(i)}" title="x^{(i)}" /></a>，
<a href="https://www.codecogs.com/eqnedit.php?latex=x^{(i)}=As^{(i)}" target="_blank"><img src="https://latex.codecogs.com/gif.latex?x^{(i)}=As^{(i)}" title="x^{(i)}=As^{(i)}" /></a>
，A和s都是未知的，x是收集到的混合信号，是已知的。

我们要做的是从x得到s，这个过程也叫盲源信号分离。

## 3、计算过程

令<a href="https://www.codecogs.com/eqnedit.php?latex=\omega&space;=A^{-1}" target="_blank"><img src="https://latex.codecogs.com/gif.latex?\omega&space;=A^{-1}" title="\omega =A^{-1}" /></a>，则<a href="https://www.codecogs.com/eqnedit.php?latex=s_{j}^{(i)}=\omega&space;x_{j}^{(i)}" target="_blank"><img src="https://latex.codecogs.com/gif.latex?s_{j}^{(i)}=\omega&space;x_{j}^{(i)}" title="s_{j}^{(i)}=\omega x_{j}^{(i)}" /></a>

但是该公式中两个矩阵不确定，<a href="https://www.codecogs.com/eqnedit.php?latex=\omega" target="_blank"><img src="https://latex.codecogs.com/gif.latex?\omega" title="\omega" /></a>和s，这样就无法得到唯一的s;还有，信号不能是高斯分布，如果是高斯分布的话，可以由不同的混合矩阵A乘上s，得到相同的x，同样无法确定S。

那如何计算呢？

### 3.1、非高斯最大化

根据中心极限定理，独立随机变量的和比原始随机变量的任意一个都更接近于高斯分布。在鸡尾酒问题中，观测信号x为相互独立的源信号的线性组合，因此x比s更接近高斯分布，或者说s比x的非高斯性更强。

这样的话可以在分离过程中s预测值<a href="https://www.codecogs.com/eqnedit.php?latex=\widehat{s}" target="_blank"><img src="https://latex.codecogs.com/gif.latex?\widehat{s}" title="\widehat{s}" /></a>的非高斯性，当非高斯型最大时表明该预测已经完成了对独立变量的分离。目前估计非高斯性的测量标准有两类：峭度和负熵。

#### 3.1.1、峭度

经典的测量非高斯的方法是kurtosis或者叫4阶累积量，设y已经被标准化，y的峭度定义为：

<a href="https://www.codecogs.com/eqnedit.php?latex=kurt(y)=E(y^{4})-3(E(y^{2}))^{2}=E(y^{4})-3" target="_blank"><img src="https://latex.codecogs.com/gif.latex?kurt(y)=E(y^{4})-3(E(y^{2}))^{2}=E(y^{4})-3" title="kurt(y)=E(y^{4})-3(E(y^{2}))^{2}=E(y^{4})-3" /></a>

对于高斯分布的随机变量y,其4阶矩为<a href="https://www.codecogs.com/eqnedit.php?latex=3(E(y^{2}))^{2}" target="_blank"><img src="https://latex.codecogs.com/gif.latex?3(E(y^{2}))^{2}" title="3(E(y^{2}))^{2}" /></a>，故峭度为0，而大多数非高斯分布峭度不为零。

峭度有正负，超高斯峭度正，亚高斯峭度负。因此可以用峭度的绝对值或者平方来度量高斯性，值为0是高斯，大于0非高斯。

峭度还有如下性质，设x、y分别为相互独立的随机变量，a为任意常数，那么：

<a href="https://www.codecogs.com/eqnedit.php?latex=kurt(x&plus;y)=kurt(x)&plus;kurt(y)" target="_blank"><img src="https://latex.codecogs.com/gif.latex?kurt(x&plus;y)=kurt(x)&plus;kurt(y)" title="kurt(x+y)=kurt(x)+kurt(y)" /></a>

<a href="https://www.codecogs.com/eqnedit.php?latex=kurt(ax)=a^{4}kurt(x)" target="_blank"><img src="https://latex.codecogs.com/gif.latex?kurt(ax)=a^{4}kurt(x)" title="kurt(ax)=a^{4}kurt(x)" /></a>

#### 3.1.2、负熵

在信息理论中，随机变量的熵可以解释为给定观测变量的信息度，随机性越大，熵值越大。离散的随机变量Y的熵定义为：

<a href="https://www.codecogs.com/eqnedit.php?latex=H(Y)=-\sum_{i}p(Y=a_{i})logP(Y=a_{i})" target="_blank"><img src="https://latex.codecogs.com/gif.latex?H(Y)=-\sum_{i}p(Y=a_{i})logP(Y=a_{i})" title="H(Y)=-\sum_{i}p(Y=a_{i})logP(Y=a_{i})" /></a>

其中，<a href="https://www.codecogs.com/eqnedit.php?latex=a_{i}" target="_blank"><img src="https://latex.codecogs.com/gif.latex?a_{i}" title="a_{i}" /></a>为Y的可能取值。

如果是连续随机变量y，概率密度函数为f(y),其熵被称为微分熵，定义为：

<a href="https://www.codecogs.com/eqnedit.php?latex=H(y)=-\int&space;f(y)logf(y)dy" target="_blank"><img src="https://latex.codecogs.com/gif.latex?H(y)=-\int&space;f(y)logf(y)dy" title="H(y)=-\int f(y)logf(y)dy" /></a>

其中，0<=f(y)<=1。且规定0log0=0。所以H(y)非负。

由信息论可知：在所有相同方差的随机变量中，高斯变量具有最大的熵。这就意味着能用熵来作为非高斯性的测度。

实际上，作为非高斯分布的度量通常使用负熵理论。设<a href="https://www.codecogs.com/eqnedit.php?latex=y_{G}" target="_blank"><img src="https://latex.codecogs.com/gif.latex?y_{G}" title="y_{G}" /></a>是与ｙ具有相同方差高斯分布的随机变量，则ｙ的负熵定义为：

<a href="https://www.codecogs.com/eqnedit.php?latex=J(y)=H(y_{G})-H(y)" target="_blank"><img src="https://latex.codecogs.com/gif.latex?J(y)=H(y_{G})-H(y)" title="J(y)=H(y_{G})-H(y)" /></a>

负熵总是非负的，当且仅当ｙ服从高斯分布时负熵值为0。ｙ的非高斯性越强，负熵越大。

用定义式来估计负熵必须要知道实际的概率密度函数，这个工作量非常大，所以，一般采取近似的办法去逼近：

<a href="https://www.codecogs.com/eqnedit.php?latex=J(y)=k[E(G(y))-E(G(y_{Gauss}))]^{2}" target="_blank"><img src="https://latex.codecogs.com/gif.latex?J(y)=k[E(G(y))-E(G(y_{Gauss}))]^{2}" title="J(y)=k[E(G(y))-E(G(y_{Gauss}))]^{2}" /></a>

其中，k为常数，<a href="https://www.codecogs.com/eqnedit.php?latex=y_{Gauss}" target="_blank"><img src="https://latex.codecogs.com/gif.latex?y_{Gauss}" title="y_{Gauss}" /></a>是均值为0，方差为1的高斯变量，函数G为非二次函数，通过选取不同的Ｇ，可得到负熵好的近似。通常，Ｇ可选如下形式：

<a href="https://www.codecogs.com/eqnedit.php?latex=G_{1}(u)=1/a_{1}logcosh(a_{1}u)" target="_blank"><img src="https://latex.codecogs.com/gif.latex?G_{1}(u)=1/a_{1}logcosh(a_{1}u)" title="G_{1}(u)=1/a_{1}logcosh(a_{1}u)" /></a>                              <a href="https://www.codecogs.com/eqnedit.php?latex=1\leq&space;a_{1}\leq&space;2" target="_blank"><img src="https://latex.codecogs.com/gif.latex?1\leq&space;a_{1}\leq&space;2" title="1\leq a_{1}\leq 2" /></a>

<a href="https://www.codecogs.com/eqnedit.php?latex=G_{2}(u)=-exp(-a_{2}u^{2}/2)" target="_blank"><img src="https://latex.codecogs.com/gif.latex?G_{2}(u)=-exp(-a_{2}u^{2}/2)" title="G_{2}(u)=-exp(-a_{2}u^{2}/2)" /></a>
<a href="https://www.codecogs.com/eqnedit.php?latex=a_{2}\approx&space;1" target="_blank"><img src="https://latex.codecogs.com/gif.latex?a_{2}\approx&space;1" title="a_{2}\approx 1" /></a>

<a href="https://www.codecogs.com/eqnedit.php?latex=G_{3}(u)=u^{4}/4" target="_blank"><img src="https://latex.codecogs.com/gif.latex?G_{3}(u)=u^{4}/4" title="G_{3}(u)=u^{4}/4" /></a>

第二个最常用；若是独立性有很强的超高斯性，且对鲁棒性要求很高时，采用第一个式子；第三个一般只用于独立成分具有亚高斯性的情况。

### 3.2、互信息最小化

设有m个随机变量<a href="https://www.codecogs.com/eqnedit.php?latex=y_{i}(i=1\cdots&space;m)" target="_blank"><img src="https://latex.codecogs.com/gif.latex?y_{i}(i=1\cdots&space;m)" title="y_{i}(i=1\cdots m)" /></a>，互信息定义为：

<a href="https://www.codecogs.com/eqnedit.php?latex=I(y_{1},y_{2},\cdots&space;,y_{m})=\sum_{i=1}^{m}H(y_{i})-H(y)=\int&space;p(y)log\frac{p(y)}{\prod_{i=1}^{m}p(y_{i})}d(y)" target="_blank"><img src="https://latex.codecogs.com/gif.latex?I(y_{1},y_{2},\cdots&space;,y_{m})=\sum_{i=1}^{m}H(y_{i})-H(y)=\int&space;p(y)log\frac{p(y)}{\prod_{i=1}^{m}p(y_{i})}d(y)" title="I(y_{1},y_{2},\cdots ,y_{m})=\sum_{i=1}^{m}H(y_{i})-H(y)=\int p(y)log\frac{p(y)}{\prod_{i=1}^{m}p(y_{i})}d(y)" /></a>

其中，p(y)是随机变量y的概率密度，<a href="https://www.codecogs.com/eqnedit.php?latex=p(y_{i})" target="_blank"><img src="https://latex.codecogs.com/gif.latex?p(y_{i})" title="p(y_{i})" /></a>是y中各分量的边缘概率密度。显然，I非负。若y各分量间相互独立，即

<a href="https://www.codecogs.com/eqnedit.php?latex=p(y)=\prod_{i=1}^{m}p(y_{i})" target="_blank"><img src="https://latex.codecogs.com/gif.latex?p(y)=\prod_{i=1}^{m}p(y_{i})" title="p(y)=\prod_{i=1}^{m}p(y_{i})" /></a>

则互信息I=0，因此互信息极小可作为相互独立的判据。

很明显以上判据在实际中无法使用，所以需要把中有关的概率密度函数展开式级数形式。在协方差相等的概率密度分布中高斯分布的熵值最大，因此展开时常用同协方差的高斯分布作为参考标准，可以展开为:

<a href="https://www.codecogs.com/eqnedit.php?latex=\frac{p(y_{i})}{p_{G}(y_{i})}=1&plus;\frac{1}{3!}k_{3}y_{i}h_{3}(y_{i})&plus;\frac{1}{4!}k_{4}y_{i}h_{4}(y_{i})&plus;\cdots" target="_blank"><img src="https://latex.codecogs.com/gif.latex?\frac{p(y_{i})}{p_{G}(y_{i})}=1&plus;\frac{1}{3!}k_{3}y_{i}h_{3}(y_{i})&plus;\frac{1}{4!}k_{4}y_{i}h_{4}(y_{i})&plus;\cdots" title="\frac{p(y_{i})}{p_{G}(y_{i})}=1+\frac{1}{3!}k_{3}y_{i}h_{3}(y_{i})+\frac{1}{4!}k_{4}y_{i}h_{4}(y_{i})+\cdots" /></a>

其中，<a href="https://www.codecogs.com/eqnedit.php?latex=p_{G}(y_{i})" target="_blank"><img src="https://latex.codecogs.com/gif.latex?p_{G}(y_{i})" title="p_{G}(y_{i})" /></a>是与<a href="https://www.codecogs.com/eqnedit.php?latex=p(y_{i})" target="_blank"><img src="https://latex.codecogs.com/gif.latex?p(y_{i})" title="p(y_{i})" /></a>具有相同方差（方差为1）和期望（期望为0）的高斯分布，k3,k4是yi的三阶四阶累积量，<a href="https://www.codecogs.com/eqnedit.php?latex=h_{n}(y_{i})" target="_blank"><img src="https://latex.codecogs.com/gif.latex?h_{n}(y_{i})" title="h_{n}(y_{i})" /></a>是n阶Hermit多项式。

### 3.3、最大似然估计

假定有一个变量s,他的概率密度函数为<a href="https://www.codecogs.com/eqnedit.php?latex=p_{s}(s)" target="_blank"><img src="https://latex.codecogs.com/gif.latex?p_{s}(s)" title="p_{s}(s)" /></a>（若是连续则为概率密度函数，离散则为概率）。为了简化，假定s是实数，还有一个随机变量x=As,A和x都是实数。令<a href="https://www.codecogs.com/eqnedit.php?latex=p_{x}(x)" target="_blank"><img src="https://latex.codecogs.com/gif.latex?p_{x}(x)" title="p_{x}(x)" /></a>是x的概率密度函数，那么如何求<a href="https://www.codecogs.com/eqnedit.php?latex=p_{x}(x)" target="_blank"><img src="https://latex.codecogs.com/gif.latex?p_{x}(x)" title="p_{x}(x)" /></a>呢？

求解之前我们先看密度函数f(x)与分布函数F(x)之间的关系：

<a href="https://www.codecogs.com/eqnedit.php?latex=F_{x}(a)&space;=&space;P(x\leqslant&space;a)=\int_{-\infty&space;}^{a}f(x)dx" target="_blank"><img src="https://latex.codecogs.com/gif.latex?F_{x}(a)&space;=&space;P(x\leqslant&space;a)=\int_{-\infty&space;}^{a}f(x)dx" title="F_{x}(a) = P(x\leqslant a)=\int_{-\infty }^{a}f(x)dx" /></a>

也就是：

<a href="https://www.codecogs.com/eqnedit.php?latex=F_{x}(x)&space;=&space;P(X\leqslant&space;x)=P(As\leqslant&space;x)=P(s\leqslant&space;\omega&space;x)=F_{s}(&space;\omega&space;x)" target="_blank"><img src="https://latex.codecogs.com/gif.latex?F_{x}(x)&space;=&space;P(X\leqslant&space;x)=P(As\leqslant&space;x)=P(s\leqslant&space;\omega&space;x)=F_{s}(&space;\omega&space;x)" title="F_{x}(x) = P(X\leqslant x)=P(As\leqslant x)=P(s\leqslant \omega x)=F_{s}( \omega x)" /></a>

又因为<a href="https://www.codecogs.com/eqnedit.php?latex=f(x)=F'(x)" target="_blank"><img src="https://latex.codecogs.com/gif.latex?f(x)=F'(x)" title="f(x)=F'(x)" /></a>，所以

<a href="https://www.codecogs.com/eqnedit.php?latex=p_{x}(x)=F_{x}^{'}(x)=F_{s}^{'}(&space;\omega&space;x)=p_{s}(&space;\omega&space;x)\left&space;|&space;\omega&space;\right&space;|" target="_blank"><img src="https://latex.codecogs.com/gif.latex?p_{x}(x)=F_{x}^{'}(x)=F_{s}^{'}(&space;\omega&space;x)=p_{s}(&space;\omega&space;x)\left&space;|&space;\omega&space;\right&space;|" title="p_{x}(x)=F_{x}^{'}(x)=F_{s}^{'}( \omega x)=p_{s}( \omega x)\left | \omega \right |" /></a>

假定每个<a href="https://www.codecogs.com/eqnedit.php?latex=s_{i}" target="_blank"><img src="https://latex.codecogs.com/gif.latex?s_{i}" title="s_{i}" /></a>都有概率密度<a href="https://www.codecogs.com/eqnedit.php?latex=p_{s}" target="_blank"><img src="https://latex.codecogs.com/gif.latex?p_{s}" title="p_{s}" /></a>，那么给定时刻原信号的联合分布为：

<a href="https://www.codecogs.com/eqnedit.php?latex=p(s)=\prod_{i=1}^{n}p_{s}(s_{i})" target="_blank"><img src="https://latex.codecogs.com/gif.latex?p(s)=\prod_{i=1}^{n}p_{s}(s_{i})" title="p(s)=\prod_{i=1}^{n}p_{s}(s_{i})" /></a>

也就是说，如果每个人发出的声音独立的话，由以上公式可得：

<a href="https://www.codecogs.com/eqnedit.php?latex=p(x)=p_{s}(w_{x})\left&space;|&space;w&space;\right&space;|=\left&space;|&space;w&space;\right&space;|\prod_{i=1}^{n}p_{s}(w_{i}^{T}x)" target="_blank"><img src="https://latex.codecogs.com/gif.latex?p(x)=p_{s}(w_{x})\left&space;|&space;w&space;\right&space;|=\left&space;|&space;w&space;\right&space;|\prod_{i=1}^{n}p_{s}(w_{i}^{T}x)" title="p(x)=p_{s}(w_{x})\left | w \right |=\left | w \right |\prod_{i=1}^{n}p_{s}(w_{i}^{T}x)" /></a>

前面提到过，如果没有先验知识，我们无法求得W和s。因此我们需要知道<a href="https://www.codecogs.com/eqnedit.php?latex=p_{s}(s_{j})" target="_blank"><img src="https://latex.codecogs.com/gif.latex?p_{s}(s_{j})" title="p_{s}(s_{j})" /></a>，我们打算选取一个概率密度函数赋给s，但是我们不能选取高斯分布的密度函数。在概率论里我们知道密度函数由累计分布函数F(x)求导得到。F(x)要满足两个性质是：单调递增和在[0,1]。我们发现sigmoid函数很适合，定义域负无穷到正无穷，值域0到1，缓慢递增。我们假定s的累积分布函数符合sigmoid函数：

<a href="https://www.codecogs.com/eqnedit.php?latex=g(s)=\frac{1}{1&plus;e^{-s}}" target="_blank"><img src="https://latex.codecogs.com/gif.latex?g(s)=\frac{1}{1&plus;e^{-s}}" title="g(s)=\frac{1}{1+e^{-s}}" /></a>

求导：

<a href="https://www.codecogs.com/eqnedit.php?latex=p_{s}(s)=g'(s)=\frac{e^{s}}{(1&plus;e^{s})^{2}}" target="_blank"><img src="https://latex.codecogs.com/gif.latex?p_{s}(s)=g'(s)=\frac{e^{s}}{(1&plus;e^{s})^{2}}" title="p_{s}(s)=g'(s)=\frac{e^{s}}{(1+e^{s})^{2}}" /></a>

这样就只剩参数w了，其似然函数：

<a href="https://www.codecogs.com/eqnedit.php?latex=l(W)=log&space;\prod_{i=1}^{m}p(x^{(i)})=\sum_{i=1}^{m}(\sum_{j=1}^{n}log&space;g'(W_{i}^{T}x^{(i)})&plus;log\left&space;|&space;W&space;\right&space;|)" target="_blank"><img src="https://latex.codecogs.com/gif.latex?l(W)=log&space;\prod_{i=1}^{m}p(x^{(i)})=\sum_{i=1}^{m}(\sum_{j=1}^{n}log&space;g'(W_{i}^{T}x^{(i)})&plus;log\left&space;|&space;W&space;\right&space;|)" title="l(W)=log \prod_{i=1}^{m}p(x^{(i)})=\sum_{i=1}^{m}(\sum_{j=1}^{n}log g'(W_{i}^{T}x^{(i)})+log\left | W \right |)" /></a>

其中<a href="https://www.codecogs.com/eqnedit.php?latex=\left&space;|&space;W&space;\right&space;|" target="_blank"><img src="https://latex.codecogs.com/gif.latex?\left&space;|&space;W&space;\right&space;|" title="\left | W \right |" /></a>求导为：

<a href="https://www.codecogs.com/eqnedit.php?latex=\Delta&space;_{W}\left&space;|&space;W&space;\right&space;|=\left&space;|&space;W&space;\right&space;|(W^{-1})^{T}" target="_blank"><img src="https://latex.codecogs.com/gif.latex?\Delta&space;_{W}\left&space;|&space;W&space;\right&space;|=\left&space;|&space;W&space;\right&space;|(W^{-1})^{T}" title="\Delta _{W}\left | W \right |=\left | W \right |(W^{-1})^{T}" /></a>

<a href="https://www.codecogs.com/eqnedit.php?latex=logg'(s)" target="_blank"><img src="https://latex.codecogs.com/gif.latex?logg'(s)" title="logg'(s)" /></a>求导为：

<a href="https://www.codecogs.com/eqnedit.php?latex=1-2g(s)" target="_blank"><img src="https://latex.codecogs.com/gif.latex?1-2g(s)" title="1-2g(s)" /></a>




## 参考文献

https://www.cnblogs.com/Ann21/p/9505623.html

https://blog.csdn.net/sinat_37965706/article/details/71330979

https://wenku.baidu.com/view/ebb635bf9a89680203d8ce2f0066f5335a8167d6.html



